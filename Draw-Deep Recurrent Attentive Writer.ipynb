{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from __future__ import print_function\n",
    "from tensorflow.examples.tutorials import mnist\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What is the core idea behind DRAW?\n",
    "DRAW extends the capability of variational auto-encoders using the following 2 methods:\n",
    "\n",
    "* (1)<u><b>Progressive Refinement:</u></b>\n",
    "    * The neural net is asked to merely improve the image, rather than finishing the image in 1shot.\n",
    "    * Each step the distribution will improve small features at a time\n",
    "    * The trick is to sample from <u>iterative refinement distribution</u> , $\\boldsymbol { P(C_t | C_{t-1})}$ rather than directly from $\\boldsymbol {P(C)}$\n",
    "    <img src='draw-1.png' height=100px width=100px>\n",
    "* (2)<u><b>Spatial Attention:</u></b>\n",
    "    * This is an extension to the above refinement to spatial domain.\n",
    "    * Here , we ask the network to improve a small region of the image at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=\"red\">PS: In the above case, there are some subtleties to settle, like how big should the attention patch be? Should the \"penstrokes\" be sharp or blurry.? These all dynamic parameters  will be learned by the DRAW model.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model\n",
    "\n",
    "The draw model uses RNN  that run for <b>T</b> steps of progressive refinement. Below pic is the neural network, where the RNNs have been unrolled across time - everything is feed forward now.\n",
    "\n",
    "<img src='draw-2.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constants \n",
    "\n",
    "data_dir = \"\"\n",
    "read_attn=True \n",
    "write_attn=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MODEL Params\n",
    "\n",
    "A=28 # width\n",
    "B = 28 # Height\n",
    "img_size = B * A # Canvas size\n",
    "enc_size = 256 # num_hidden size / num_out in LSTM\n",
    "dec_size = 256\n",
    "\n",
    "read_n = 5\n",
    "write_n = 5\n",
    "\n",
    "#Below logic to set read window if attention switched on/off\n",
    "read_size = 2* read_n * read_n if read_attn else 2 * img_size\n",
    "write_size = write_n * write_n if write_attn else img_size\n",
    "\n",
    "z_size=10 # QSampler output size\n",
    "\n",
    "T =10 # MNIST Generation sequence length\n",
    "batch_size = 100\n",
    "train_iters = 10000\n",
    "learning_rate = 1e-3\n",
    "eps = 1e-8 # epsilon for numerical stability\n",
    "\n",
    "\n",
    "DO_SHARE=None # hack for variable_scope(reuse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now comes the model construction part\n",
    "X = tf.placeholder(dtype=tf.float32,shape=(batch_size,img_size))\n",
    "e = tf.random_normal((batch_size,z_size),mean=0,stddev=1) # QSampler noise standard normal distribution\n",
    "lstm_enc = tf.contrib.rnn.LSTMCell(enc_size,state_is_tuple=True)\n",
    "lstm_dec = tf.contrib.rnn.LSTMCell(dec_size,state_is_tuple=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single cell eqn:<br>\n",
    "\n",
    "<img src='draw-3.png' width =300px height=300px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear(x,output_dim):\n",
    "    \"\"\"\n",
    "    affine transformation Wx+b\n",
    "    assumes x.shape=(batch_size,num_features)\n",
    "    \"\"\"\n",
    "    w = tf.get_variable(\"w\",[x.get_shape()[1],output_dim])\n",
    "    b = tf.get_variable(\"b\",[output_dim], initializer=tf.constant_initializer(0.0))\n",
    "    return tf.matmul(x,w)+b\n",
    "\n",
    "\n",
    "def filter_bank(gx,gy,sigma_sqr,delta,N):\n",
    "    grid_i = tf.reshape(tf.cast(tf.range(N),tf.float32),[1,-1])\n",
    "    mu_x = gx + (grid_i - N/2 - 0.5) * delta\n",
    "    mu_y = gy + (grid_i - N/2 - 0.5) * delta\n",
    "    a = tf.reshape(tf.cast(tf.range(A),tf.float32),[1,1,-1])\n",
    "    b = tf.reshape(tf.cast(tf.range(B),tf.float32),[1,1,-1])\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "def attention_window(scope,h_dec,N):\n",
    "    with tf.variable_scope(scope,reuse=DO_SHARE):\n",
    "        params = linear(h_dec,5)\n",
    "        \n",
    "    gx_tilde,gy_tilde,log_sigma2,log_delta,log_gamma = tf.split(params,5,1)\n",
    "    gx = (A+1)/2 * (gx_tilde+1)\n",
    "    gy = (B+2)/2 * (gy_tilde+1)\n",
    "    sigma_sqr = tf.exp(log_sigma2) # This ensures that the sigma goes in positive value range\n",
    "    delta = (max(A,B)-1)/ (N-1) * tf.exp(log_delta) # batch x N\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bce(targ,out):\n",
    "    return -(targ* tf.log(out+eps) + ((1.0-targ)* tf.log(1.0-out+eps)))\n",
    "\n",
    "def read_no_attn(x,x_cap,h_dec_prev):\n",
    "    return tf.concat([x,x_cap],axis=1)\n",
    "\n",
    "def read_with_attn(x,x_cap,h_dec_prev):\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#state variables\n",
    "cs = [0.0]*T #Sequence of canvases\n",
    "mus,logsigmas,sigmas = [0]*T,[0]*T,[0]*T #Gaussian params generated by SampleQ. We will need this for computing loss\n",
    "\n",
    "#initial states\n",
    "h_dec_prev = tf.zeros((batch_size,img_size))\n",
    "enc_state = lstm_enc.zero_state(batch_size,tf.float32)\n",
    "dec_state = lstm_dec.zero_state(batch_size,tf.float32)\n",
    "\n",
    "#draw model\n",
    "\n",
    "#construct the unrolled graph\n",
    "#Single feed forwards....\n",
    "for t in range(T):\n",
    "    c_prev = tf.zeros((batch_size,img_size)) if t==0 else cs[t-1]\n",
    "    x_cap = X-tf.sigmoid(c_prev)\n",
    "    r = read(X,x_cap,h_dec_prev)\n",
    "    h_enc,enc_state = encode(enc_state,tf.concat([r,h_dec_prev],axis=1))\n",
    "    z,mus[t],logsigmas[t],sigmas[t]=sampleQ(h_enc)\n",
    "    h_dec,dec_state = decode(dec_state,z)\n",
    "    cs[t] = c_prev + write(h_dec)\n",
    "    DO_SHARE=True\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
