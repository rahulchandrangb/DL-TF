{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from __future__ import print_function\n",
    "from tensorflow.examples.tutorials import mnist\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What is the core idea behind DRAW?\n",
    "DRAW extends the capability of variational auto-encoders using the following 2 methods:\n",
    "\n",
    "* (1)<u><b>Progressive Refinement:</u></b>\n",
    "    * The neural net is asked to merely improve the image, rather than finishing the image in 1shot.\n",
    "    * Each step the distribution will improve small features at a time\n",
    "    * The trick is to sample from <u>iterative refinement distribution</u> , $\\boldsymbol { P(C_t | C_{t-1})}$ rather than directly from $\\boldsymbol {P(C)}$\n",
    "    <img src='draw-1.png' height=100px width=100px>\n",
    "* (2)<u><b>Spatial Attention:</u></b>\n",
    "    * This is an extension to the above refinement to spatial domain.\n",
    "    * Here , we ask the network to improve a small region of the image at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=\"red\">PS: In the above case, there are some subtleties to settle, like how big should the attention patch be? Should the \"penstrokes\" be sharp or blurry.? These all dynamic parameters  will be learned by the DRAW model.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model\n",
    "\n",
    "The draw model uses RNN  that run for <b>T</b> steps of progressive refinement. Below pic is the neural network, where the RNNs have been unrolled across time - everything is feed forward now.\n",
    "\n",
    "<img src='draw-2.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constants \n",
    "\n",
    "data_dir = \"\"\n",
    "read_attn=True \n",
    "write_attn=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MODEL Params\n",
    "\n",
    "A=28 # width\n",
    "B = 28 # Height\n",
    "img_size = B * A # Canvas size\n",
    "enc_size = 256 # num_hidden size / num_out in LSTM\n",
    "dec_size = 256\n",
    "\n",
    "read_n = 5\n",
    "write_n = 5\n",
    "\n",
    "#Below logic to set read window if attention switched on/off\n",
    "read_size = 2* read_n * read_n if read_attn else 2 * img_size\n",
    "write_size = write_n * write_n if write_attn else img_size\n",
    "\n",
    "z_size=10 # QSampler output size\n",
    "\n",
    "T =10 # MNIST Generation sequence length\n",
    "batch_size = 100\n",
    "train_iters = 10000\n",
    "learning_rate = 1e-3\n",
    "eps = 1e-8 # epsilon for numerical stability\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now comes the model construction part\n",
    "X = tf.placeholder(dtype=tf.float32,shape=(batch_size,img_size))\n",
    "e = tf.random_normal((batch_size,z_size),mean=0,stddev=1) # QSampler noise standard normal distribution\n",
    "lstm_enc = tf.contrib.rnn.LSTMCell(enc_size,state_is_tuple=True)\n",
    "lstm_dec = tf.contrib.rnn.LSTMCell(dec_size,state_is_tuple=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear(x,output_dim):\n",
    "    \"\"\"\n",
    "    affine transformation Wx+b\n",
    "    assumes x.shape=(batch_size,num_features)\n",
    "    \"\"\"\n",
    "    w = tf.get_variable(\"w\",[x.get_shape()[1],output_dim])\n",
    "    b = tf.get_variable(\"b\",)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
